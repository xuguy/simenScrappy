# Project Description

## Using Kaggle Computing Platform to Run a Web Scraping Project

This repository demonstrates the steps to run a web scraping project using the Kaggle computing platform. However, due to access restrictions on websites located in China, we were unable to run the web scraping notebook directly on Kaggle. Instead, we tested the code execution and output generation through Kaggle's environment.

## Files Description

1. **`imenScrap.ipynb`** and **`scrap.py`**: These are two runnable code files. Their content is essentially the same, but the `.ipynb` version is required for execution on Kaggle.
2. **`simenSteamID.csv`**: This is a CSV file containing data of the first 1000 users of Simen. This file is deprecated and should not be used.
3. **`test-notebook.log`** and **`testOutputFile.csv`**: These are the output files generated during the test run on Kaggle. We used the standard procedure to download these outputs from Kaggle by executing the command `kaggle kernels output xgy2718/test-notebook`.

## Procedure

1. **Prepare the code and test locally**: Before running the code on Kaggle, make sure it is executable on your local machine.
2. **Initialize Kaggle Kernel**: Run `kaggle init` to create the `kernel-metadata.json` file, and fill in the necessary information.
3. **Upload the notebook to Kaggle**: Use the `kaggle push` command to upload the `.ipynb` file to Kaggle.
4. **Download the output from Kaggle**: After running the code on Kaggle, use the following command to download the output generated by the code.

## Problems Encountered

1. **Access Denied to Targeted Webpage**: The targeted webpage is located in China, and Kaggle's servers are not in China, so access to the webpage is blocked. This prevents us from running the web scraping notebook directly on Kaggle.
2. **Workaround**: Since the web scraping was not feasible on Kaggle, we decided to focus on testing the other code functionalities. Specifically, we tested the execution of the code and verified that the output was as expected.

## Conclusion

While we couldn't run the web scraping code on Kaggle due to access restrictions, we were able to test the platform's environment and ensure the code's functionality. In the future, you might need to run the actual scraping on a server located in the same region as the target website or use a VPN/proxy to bypass regional access limitations.

## Stage 2: Migrate project to Server

1. get a Ali Cloud Ubuntu Server: `Ubuntu 20.24`->重置密码，设置密码，用于远程连接服务器
2. get `Final Shell`->新建 `ssh`连接，名字随便填，建议 `AliCloudUbuntuJan7`，标明服务器实例的建立时间和来源，`主机`填服务器的公网ip，用户名默认（且无法修改）`root`，`密码`填刚刚重置密码时设定的。连接即可进入terminal
3. `wget https://repo.anacond.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh` 用Linux命令下载安 `Anaconda`环境的安装包（安装完成后可以用 `rm`删除）
4. 安装：`bash Anaconda3-2024.10-1-Linux-x86_64.sh`，按住 `Enter`，然后 `yes`，可以选择安装目录，但是我没选
